{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12788,
     "status": "ok",
     "timestamp": 1731010486833,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "Weg3sgi-83v1",
    "outputId": "8ed5d2f3-3f01-41d1-e59c-2b695fc0d9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-openai\n",
      "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-experimental\n",
      "  Downloading llama_index_experimental-0.4.0-py3-none-any.whl.metadata (884 bytes)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.7 (from llama-index-llms-openai)\n",
      "  Downloading llama_index_core-0.11.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (1.52.2)\n",
      "Collecting llama-index-finetuning<0.3.0,>=0.2.0 (from llama-index-experimental)\n",
      "  Downloading llama_index_finetuning-0.2.1-py3-none-any.whl.metadata (992 bytes)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-experimental) (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.10.10)\n",
      "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.10.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.2)\n",
      "Collecting nltk>3.8.1 (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
      "Collecting llama-index-embeddings-adapter<0.3.0,>=0.2.0 (from llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading llama_index_embeddings_adapter-0.2.2-py3-none-any.whl.metadata (688 bytes)\n",
      "Collecting llama-index-llms-azure-openai<0.3.0,>=0.2.0 (from llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading llama_index_llms_azure_openai-0.2.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting llama-index-llms-mistralai<0.3.0,>=0.2.0 (from llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading llama_index_llms_mistralai-0.2.7-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0 (from llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading llama_index_postprocessor_cohere_rerank-0.2.1-py3-none-any.whl.metadata (723 bytes)\n",
      "Requirement already satisfied: sentence-transformers>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (3.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-experimental) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-experimental) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-experimental) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (2.5.0+cu121)\n",
      "Collecting azure-identity<2.0.0,>=1.15.0 (from llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mistralai>=1.0.0 (from llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading mistralai-1.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting cohere<6.0.0,>=5.1.1 (from llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading cohere-5.11.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-experimental) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (4.44.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (0.24.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.1.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting azure-core>=1.31.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (43.0.3)\n",
      "Collecting msal>=1.30.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading msal-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse==0.4.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (0.19.1)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (24.1)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from mistralai>=1.0.0->llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (0.2.0)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from mistralai>=1.0.0->llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (0.4.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.3.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (1.17.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (2.9.0)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (3.0.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning<0.3.0,>=0.2.0->llama-index-experimental) (2.22)\n",
      "Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_experimental-0.4.0-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_core-0.11.22-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_finetuning-0.2.1-py3-none-any.whl (30 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_embeddings_adapter-0.2.2-py3-none-any.whl (4.5 kB)\n",
      "Downloading llama_index_llms_azure_openai-0.2.2-py3-none-any.whl (6.3 kB)\n",
      "Downloading llama_index_llms_mistralai-0.2.7-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_postprocessor_cohere_rerank-0.2.1-py3-none-any.whl (2.9 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.11.3-py3-none-any.whl (248 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.7/248.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mistralai-1.1.0-py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading msal-1.31.0-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: dirtyjson, types-requests, tenacity, portalocker, parameterized, nltk, mypy-extensions, marshmallow, jsonpath-python, httpx-sse, fastavro, typing-inspect, tiktoken, azure-core, mistralai, dataclasses-json, msal, llama-index-core, cohere, msal-extensions, llama-index-postprocessor-cohere-rerank, llama-index-llms-openai, llama-index-llms-mistralai, llama-index-embeddings-adapter, azure-identity, llama-index-llms-azure-openai, llama-index-finetuning, llama-index-experimental\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed azure-core-1.32.0 azure-identity-1.19.0 cohere-5.11.3 dataclasses-json-0.6.7 dirtyjson-1.0.8 fastavro-1.9.7 httpx-sse-0.4.0 jsonpath-python-1.0.6 llama-index-core-0.11.22 llama-index-embeddings-adapter-0.2.2 llama-index-experimental-0.4.0 llama-index-finetuning-0.2.1 llama-index-llms-azure-openai-0.2.2 llama-index-llms-mistralai-0.2.7 llama-index-llms-openai-0.2.16 llama-index-postprocessor-cohere-rerank-0.2.1 marshmallow-3.23.1 mistralai-1.1.0 msal-1.31.0 msal-extensions-1.2.0 mypy-extensions-1.0.0 nltk-3.9.1 parameterized-0.9.0 portalocker-2.10.1 tenacity-8.5.0 tiktoken-0.8.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-openai llama-index-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oG-VodnB9O8K"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "from llama_index.experimental.query_engine.pandas import (\n",
    "    PandasInstructionParser,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import PromptTemplate\n",
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1731010536760,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "er6WUuwpQvd2",
    "outputId": "f3b5b61b-1597-4a9a-82d2-a4a986f1a4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-07 20:15:36--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 57726 (56K) [text/plain]\n",
      "Saving to: ‘titanic_train.csv’\n",
      "\n",
      "titanic_train.csv   100%[===================>]  56.37K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-11-07 20:15:36 (5.54 MB/s) - ‘titanic_train.csv’ saved [57726/57726]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fspTKNgu9WlL"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1731011423912,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "yPPyeSo9UfLW"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/content/sample_data/OTL_edited.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24640,
     "status": "ok",
     "timestamp": 1731011450485,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "gV53hDV6TCmJ",
    "outputId": "df0c27dc-feb7-406a-e790-a317c695707c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1731011457121,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "ain1ZC-F_INB"
   },
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1731011458276,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "2jjvfj5Y-RGU"
   },
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str, df_str=df.head(5)\n",
    ")\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1731011459715,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "V3VA3gnS-RRB"
   },
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# add link from response synthesis prompt to llm2\n",
    "qp.add_link(\"response_synthesis_prompt\", \"llm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1984,
     "status": "ok",
     "timestamp": 1731010584784,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "PXz4Pmdf-RaT",
    "outputId": "16fe6917-dfda-4676-eceb-631c5c6392e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What is the correlation between survival and gender\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What is the correlation between survival and gender\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "   survived  pclass                                               name  ...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['survived'].corr(df['sex'].astype('category').cat.codes)\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What is the correlation between survival and gender\n",
      "pandas_instructions: assistant: df['survived'].corr(df['sex'].astype('category').cat.codes)\n",
      "pandas_output: -0.5433513806577553\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: What is the correlation between survival and gender\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['survived'].corr(df['sex'].astype(...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query_str=\"What is the correlation between survival and gender\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1731010589231,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "MYeSMEuG-Rd2",
    "outputId": "1838d34d-744d-44b6-dcdf-7264d51e8adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between survival and gender is -0.54, indicating a moderate negative correlation. This suggests that gender does have an impact on survival rates, with females more likely to survive compared to males.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1660,
     "status": "ok",
     "timestamp": 1731011506447,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "dxZXvbzf-Ri2",
    "outputId": "5a13dec6-b659-4676-8d96-67165ed31006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What is the mean of copyright of books\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What is the mean of copyright of books\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "   OTL ID                               Title  Copyright Year  \\\n",
      "0     4...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['Copyright Year'].mean()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What is the mean of copyright of books\n",
      "pandas_instructions: assistant: df['Copyright Year'].mean()\n",
      "pandas_output: 2013.3578595317726\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: What is the mean of copyright of books\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['Copyright Year'].mean()\n",
      "\n",
      "Pandas Output: 2013.3...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#response = qp.run(\n",
    "#    query_str=\"What is the mean of copyright of books\",\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1731011515227,
     "user": {
      "displayName": "Xiaoqing Yao",
      "userId": "12214632822249908548"
     },
     "user_tz": 300
    },
    "id": "safycVOKUwXN",
    "outputId": "a6fc11b4-38e1-4f7d-b828-046fa45bef97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean copyright year of books is approximately 2013.36.\n"
     ]
    }
   ],
   "source": [
    "#print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vsOmk5ZU5Fi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
